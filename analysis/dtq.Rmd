---
title: "Dog Trainer Questionnaire vs Outcome (Fail, Success) "
author: "Marinara Marcato"
output:
  html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/marinara.marcato/Project/Scripts/dog_questionnaires")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
#install.packages("ggpubr")
library(DescTools)
library(ggplot2)
library(cowplot)
library(plyr)
library(dplyr)
library(tidyverse)
library(rstatix)
library(ggpubr)
library(car) # multicollinearity


library(mlbench)
library(caret)
library(reshape2)

```

# Introduction 
This document tests the hypothesis that there is a difference in behaviours reported in the standardised questionnaire Monash Canine Personality Questionnaire - Revised considering dog's training outcome.

# Data Exploration

Importing data and converting to adequate data types.
```{r, echo = FALSE}
dtq = read.csv('data//2022-06-27-DTQ_MCPQ-R.csv', stringsAsFactors=TRUE)
# colnames(dtq)
# converting date types
dtq$Timestamp = as.Date(dtq$Timestamp, format= "%Y-%m-%d")
dtq$DOB = as.Date(dtq$DOB, format= "%Y-%m-%d")
dtq$DOA = as.Date(dtq$DOA, format= "%Y-%m-%d")
dtq$End.Date = as.Date(dtq$End.Date, format= "%Y-%m-%d")
dtq$Duration = as.numeric(gsub(" .*$", "", dtq$Duration))
```
## Demographics
The number of dogs in the Dog Trainer Questionnaire dataset.
```{r, echo = FALSE}
cat('Number of dogs:', length(dtq$Code))
cat('Training Outcome:')
table(dtq$Outcome)
```

Analysing categorical demographic data: Sex, Breed. There was only one German Shepherd and two Golden Doodle in the sample, their breeds were relabeled as "Other" for the data analysis.
```{r, echo = FALSE}
print(table(dtq$Sex))
print("Original classes")
table(dtq$Breed)
# merging breed categories
levels(dtq$Breed)[levels(dtq$Breed) == "LRx"] <- "LRxGR"
levels(dtq$Breed)[levels(dtq$Breed) =="GS" | levels(dtq$Breed) =="GRxPoodle"] <- "Other"
print("Processed classes")
table(dtq$Breed)
```

Analysing age at assessment and duration of training until withdrawal:
```{r, echo = FALSE}
dtq$Age.at.Assessment <- dtq$Timestamp - dtq$DOB
cat('Age at Assessment: Mean', round(mean(dtq$Age.at.Assessment)/30.417,2), 
            'Standard Deviation', round(sd(dtq$Age.at.Assessment)/30.417, 2))

# Duration of training before withdrawal in weeks
duration <- dtq %>% filter(Outcome == "Fail") %>% pull(Duration)/7
summary(duration)
hist(duration)
```

## Descriptive Statistics
The MCPQ-R contains 26 items which were scored by the Trainer in a scale from 1 to 6.
The questionnaire data are kept as integers, rather than being converted to factors, so the information about the ordering is kept.
The descriptive statistics of the questionnaire data shown below are saved as a csv.  

<!-- 
Other potential variables for inclusion in the model:
"PR.Sup" -> Alison = 5, Catherine = 6, DSM = 3, Frances = 11, Graham = 24, Mags = 3, Rose = 23, UKPR = 11
"Source" -> IGDB = 60, AADI =3, Cesecah = 1, GDBUK = 16, Private breeder = 8, PRV breeder = 1 -->

```{r, echo = FALSE}
# selecting predictive features
data = dtq %>% select(contains(c("Extraversion", "Motivation", "Training",
 "Amicability", "Neuroticism", "Sex", "Breed", "Outcome")))  %>% select(!contains("Comments"))
data$Outcome <- relevel(data$Outcome, "Success")
cat("Dimension of the dataset including the dependent variable: ", dim(data))
# str(data)
# calculate descriptive statistics on the dataset
stats <- data.frame(do.call(rbind, lapply(data, summary)))
print(stats)
# save descriptive statistics of the dataset to csv
write.csv(stats, "analysis/dtq-stats.csv") 
```

## Univariate Logistic Regression
Testing if variables have a statistically significant association with Outcome (Fail, Success). 
Univariate Logistic Regression models use each feature individually to predict the outcome.
Features with a p_value < 0.2 were kept for the multicollinearity analysis and further multivariate logistic regression model.

```{r, echo = FALSE}
# univariate logistic regression using one predictor and outcome
lr_models <- lapply(data[-length(data)], function(x) glm(formula = Outcome ~ x, data = data, family = binomial(link = logit)))
str(data[-length(data)])
lr_results <- data.frame(do.call(rbind, lapply(lr_models, function(x) c(round(coef(summary(x))[2,4],4), x$deviance))))
colnames(lr_results) <- c("p_value", "deviance")
lr_results$significant_0.05 <- (lr_results$p_value < 0.05)
lr_results$significant_0.1 <- (lr_results$p_value < 0.1)
lr_results$significant_0.2 <- (lr_results$p_value < 0.2)
# lr_results[order(lr_results$p_value),]
print("Number of variables considering each level of significance using Logistic test")
print(colSums(lr_results[,3:5], na.rm = TRUE))
print(lr_results[lr_results$significant_0.05 == TRUE, 'p_value', drop = FALSE])

feat_lr = rownames(lr_results[lr_results$p_value < 0.2,])
data_lr <- data %>% select(all_of(feat_lr), Outcome)
```

## Multicollinearity 
The Variance Inflation Factor (VIF) was calculate to assess multicollinearity. 
VIF = 1 no correlation, 5 < VIF < 10 moderate correlation, VIF > 10 high multicollinearity. 
VIF larger than 5 or 10 is large and indicate a high level of multicollinearity and should be further processed.

```{r, echo = FALSE}
# including all features selected by lr test
model_lr <- glm(Outcome ~ ., data=data_lr, family = binomial(link = logit)) 
summary(model_lr)
print(VIF(model_lr))
```

## Principal Component Analysis (PCA)
Principal component analysis will be used to combine features that showed high multicollinearity.
As no variables showed VIF > 5, no PCA was performed in this model.

## Visualization
Plotting features selected considering univariate logistic regression pvalue results.

```{r, echo = FALSE}

plotseries <- function(var){
    plot1 <- ggplot(dtq, aes_string( x = var, fill = 'Outcome')) + 
            geom_bar(position = "dodge") +
            theme(legend.position = c(0.13,0.88)) +
            scale_x_discrete("Rating", limits = c(1:6), breaks = c(1:6), labels = c(1:6)) +
            expand_limits(x = c(1,6))

    plot2 <- ggplot(dtq, aes_string( x = 'Outcome', y = var)) + 
            geom_boxplot(position = "dodge", aes(colour = Outcome))  +
            theme(legend.position = "none") +
            scale_y_discrete("Rating", limits = c(1:6), breaks = c(1:6), labels = c(1:6)) +
            expand_limits(y = c(1,6)) +
            ylab("Rating")
    plot3 <- plot_grid(plot1, plot2, rel_widths = c(2, 1), labels = "AUTO")
    

    title <- ggdraw() + 
      draw_label(gsub("[.]", " - ", var), fontface = 'bold')
    
    plot <- plot_grid(title, plot3, ncol = 1, rel_heights = c(0.1, 1))

    suppressMessages(ggsave(paste("output//model-dtq//", gsub("[.]", "-", var), ".png", sep = "") 
          , plot))
    
    plot
}
lapply(feat_lr, plotseries)

```

# Recursive Feature Elimination (RFE) + Multivariate Logistic Regression (LR)

Selecting only features that had a pvalue < 0.2 in univariate logistic regression analysis and no collinearity issues to estimate Outcome using Logistic Regression.
The model also implements Backwards Feature Selection with Recursive Feature Elimination using Leave One Subject Out Cross Validation.
[Caret RFE](https://search.r-project.org/CRAN/refmans/caret/html/rfe.html), 
[RFE Control](https://search.r-project.org/CRAN/refmans/caret/html/rfeControl.html), 
[Example with RF](https://towardsdatascience.com/effective-feature-selection-recursive-feature-elimination-using-r-148ff998e4f7), [ROC as metric](https://stackoverflow.com/questions/18242692/r-package-caret-rfe-function-how-to-customize-metric-to-use-auc).

```{r, echo = FALSE}
# feature selection using recursive feature elimination (RFE)

# Setting ROC as the metric for the Logistic Regression function
lrFuncs$summary <- twoClassSummary

ctrl <- rfeControl(functions = lrFuncs,     # logistic regression
                    method = "LOOCV",       # Leave One Out Cross Validation
                    verbose = FALSE)

# Recursive Feature Elimination with feat_lr
rfe_lr <- rfe(Outcome ~ . ,                 # predict Outcome using all other variables
            data = data_lr,                 # selecting the features from univariate lr
                   sizes = c(1:length(data_lr)-1),
                   rfeControl = ctrl,
                   metric = "ROC")

warnings()
print(rfe_lr)
ggplot(data = rfe_lr, metric = "ROC") + theme_bw()
cat("Features in the model that delivered the best ROC", predictors(rfe_lr))

model_lr <- rfe_lr$fit
summary(model_lr)
```
RFE chose 6 variables when optimizing for AUC-ROC, namely:
"Training.Trainable", "Amicability.Friendly", "Motivation.Persevering", "Training.Biddable", "Extraversion.Hyperactive", "Amicability.Easy.going".
Analysing deviance of full model compared to the null model. 
Reduction in deviance must be significant (chi-squared test) for the model to be considered a good fit.
```{r, echo = FALSE}
dev_null_residual <- function(model){
    dev = model$null.deviance - model$deviance
    df = model$df.null - model$df.residual
    cat('\ndeviance difference: ', dev)
    cat('\ndf difference: ', df)
    cat('\nlevel of significance: ', 1 - pchisq(dev, df, lower.tail = FALSE))
}

dev_null_residual(model_lr)
```

## Interpretation
The best Logistic Regression model is used to investigate the effect of each variable on the training outcome.

Three variables showed some level of statistical significance, namely:
- "Training.Trainable" (p<0.05), for each unit increase the OR was smaller by 0.228 (less likely to be withdrawn)
- "Motivation.Persevering" (p<0.01), each unit increase the OR was smaller by 0.418 (less likely to be withdrawn)
- "Amicability.Easy.going" (p<0.1), each unit increase the OR was smaller by 0.531 (less likely to be withdrawn)

```{r, echo = FALSE}
# exponentiate the coefficentes to get the odd ratio and their confidence intervals
## odds ratios and 95% CI using profiled log-likelihood
df_model <- as.data.frame(coef(summary(model_lr)))
df_model$OR <- exp(df_model$Estimate)
df_model <- cbind(df_model, exp(confint(model_lr, level = 0.95)))
print("Results from the model created")
print(df_model)
rownames(df_model)[2:7]
```



## Diagnostics
1. Index plot: residuals vs case number
2. Leverage cases
3. Influence cases

```{r, echo = FALSE}
diagnostics <- function(model){
    h <- lm.influence(model)$hat
    rpear <- residuals(model, "pearson")/sqrt(1-h)
    rdev <- residuals(model, "deviance")/sqrt(1-h)
    phat <- model$fitted.values
    D <- rpear*rpear*h/(2**(1-h))
    diagnostic <- data.frame(data$Outcome, phat, h, rpear, rdev, D)
    return(diagnostic)

    plot(rpear, main="Index Plot of Pearson Residuals")
    plot(model$linear.predictors, rpear, main = "Plot of Pearson Residuals vs Linear Predictor")
}

diag_lr <- diagnostics(model_lr)
diag_lr[order(diag_lr$rpear, decreasing = TRUE),]
```
<!-- 
## Feature Importance -->
```{r, echo = FALSE}
importance <- data.frame(feature = row.names(varImp(rfe_lr))[1:8],
                          importance = varImp(rfe_lr)[1:8, 1])
```