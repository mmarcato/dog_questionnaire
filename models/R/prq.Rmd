---
title: "Puppy Raiser Questionnaire vs Outcome (Success, Fail)"
author: "Marinara Marcato"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/marinara.marcato/Project/Scripts/dog_questionnaires")
knitr::opts_chunk$set(echo = TRUE)
#install.packages("ggpubr")
library(DescTools)
library(ggplot2)
library(cowplot)
library(plyr)
library(dplyr)
library(tidyverse)
library(rstatix)
library(ggpubr)
```

## Introduction 
This document tests the hypothesis that there is a difference in behaviours reported in the standardised questionnaire Canine Behavioural Assessement & Research Questionnaire (C-BARQ) considering dog's training outcome.

## Data Exploration
### Columns: Features
Below are the questionnaire items (variables) that were scored by the Puppy Raise in a scale from 'Never', 'Seldom', 'Sometimes', 'Usually', 'Always'. 

```{r, echo = FALSE}
prq = read.csv('data//2022-05-10-PRQ_C-BARQ.csv')
colnames(prq)
# converting date types
prq$Timestamp = as.Date(prq$Timestamp, format= "%Y-%m-%d")
prq$DOB = as.Date(prq$DOB, format= "%Y-%m-%d")
prq$DOA = as.Date(prq$DOA, format= "%Y-%m-%d")
prq$End.Date = as.Date(prq$End.Date, format= "%Y-%m-%d")
prq$Duration  = as.Date(prq$End.Date, format= "%Y-%m-%d")
```

### Rows: Dogs
The number of dogs in the Puppy Raiser Questionnaire dataset. Selection criteria: dogs with a defined training outcome.
```{r, echo = FALSE}
cat('Number of dogs:', length(prq$Code))
cat('Training Outcome:')
table(prq$Outcome)
```
Analysing categorical demographic data: Sex, Breed. There was only one German Shepherd and Golden Doodle in the sample, their breeds were relabeled as "Other" for the data analysis.
```{r, echo = FALSE}
print(table(prq$Sex))
print("Original classes")
table(prq$Breed)
# merging breed categories
levels(prq$Breed)[levels(prq$Breed) == "LRx"] <- "LRxGR"
levels(prq$Breed)[levels(prq$Breed) =="GS" | levels(prq$Breed) =="GRxPoodle"] <- "Other"
print("Processed classes")
table(prq$Breed)
```

Analysing age at assessment:
```{r, echo = FALSE}
prq$Age.at.Assessment <- prq$Timestamp - prq$DOB
cat('Age at Assessment: Mean', round(mean(prq$Age.at.Assessment)/30.417, 2), 
            'Standard Deviation', round(sd(prq$Age.at.Assessment)/30.417, 2))
```

## Descriptive Statistics
Calculate and save the descritive statist of the features selected for hypothesis testing the association with training outcome. 

```{r, echo = FALSE}
# select features for predictive analysis
data = prq %>% select(starts_with(c("X⁠", "F_")), "Sex", "Breed", "Outcome")
# transform Outcome in 0 = Success, 1 = Fail
levels(prq$Outcome)[levels(prq$Outcome) == "Success"] <- 0
(prq$Outcome)


# check the classes of each column
dim(data)
# calculate descriptive statistics on the dataset
stats <- data.frame(do.call(rbind, lapply(data, summary)))

data[1:114] <- lapply(data[1:114], function(x) as.integer(x))

# calculate number of missing values, there is something weird about the NAs calculations using summary
stats <- cbind(stats, colSums(is.na(data)))
colnames(stats)[8] <- "Missing"
print('Features with more than 5 NAs')
hist(stats$Missing, breaks = 20)
print(stats[order(stats$Missing, decreasing = TRUE)[1:15], 'Missing', drop = FALSE])

# 28 NAs -> Item 49 nails clipped by someone in the house
# 12-10 NAs -> Because of no other dog  in household -> Items 33,34,32,35

# FACTOR CALCULATIONS
    # 1.'Stranger-directed aggression' score = (questionnaire items 10 + 11 + 12 + 15 + 16 + 18 + 20 + 21 + 22 + 28)/10.
    # 2.'Owner-directed aggression' score = (items 9 + 13 + 14 + 17 + 19 + 25 + 30 + 31)/8.
    # 3.'Dog-directed aggression' = (items 23 + 24 + 26 + 29)/4
    # 4.'Dog-directed fear' = (items 45 + 46 + 52 + 53)/4.
        # Item 33 approached in 
    # 5.'Dog rivalry'(familiar dog aggression) score = (items 32 + 33 + 34 + 35)/4
    # 6.'Trainability' score = (items 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8)/8—remember to reverse scoring order for items 5, 6 & 7 (see above).
        
    # 7.'Chasing' score = (items 27 + 74 + 75 + 76)/4
    # 8.'Stranger-directed fear' score = (items 36 + 37 + 39 + 40)/4
    # 9.'Nonsocial fear' score = (items 38 + 41 + 42 + 44 + 47 + 48)/6
    # 10.'Separation-related problems' score = (items 54 + 55 + 56 + 57 + 58 + 59 + 60 + 61)/8

    # 11.'Touch sensitivity' score = (items 43 + 49 + 50 + 51)/4
    # 12.'Excitability' score = (items 62 + 63 + 64 + 65 + 66 + 67)/6
    # 13.'Attachment/attention-seeking' score = (items  68 + 69 + 70 + 71 + 72 + 73)/6
    # 14.'Energy' score = (items 91 + 92)/2

# save descriptive statistics of the dataset to csv
write.csv(stats, "models/R/prq-stats.csv") 
```

## Data Analysis
Logistic Regression one-way analysis of variance test was used to investigate whether there was a statistically significant difference between the behaviours reported by Puppy Raisers and the Training Outcome of the dogs.
C-BARQ Correlation with Training Outcome. 

I can use either or both pvalue and reduction in significance for building models.
```{r, echo = FALSE}
# univariate logistic regression using one predictor and outcome
lr_models <- lapply(data[-length(data)], function(x) summary(glm(formula = Outcome ~ x, data = data, family = binomial(link = logit), na.action = na.exclude)))
lr_result <- lapply(lr_models, function(x) c(coef(x), x$deviance))

## univariate models with 3 dfs (Breed)
lr_breeds <- data.frame(transpose(lr_result[116]))
colnames(lr_breeds) <- c("estimate_0", "se_0", "z_value_0", "p_value_0", 
                    "estimate_1", "se_1", "z_value_1", "p_value_1", 
                    "estimate_2", "se_2", "z_value_2", "p_value_2", "deviance")
print(unique(data$Breed))
cat('\n\nDifference between LRxGR and LR: \t', lr_breeds$p_value_1, '\nnot significant')
cat('\n\nDifference between LRxGR and Other: \t', lr_breeds$p_value_2, '\nnot significant')


## univariate models with up to 2 dfs (questionnaire items are treated as numerical)
lr_results <- data.frame(do.call(rbind,lr_result[1:115]))
colnames(lr_results) <- c("estimate_0", "se_0", "z_value_0", "p_value_0", 
                    "estimate_1", "se_1", "z_value_1", "p_value_1", "deviance")

# pvalue analysis
lr_results$significant_0.05 <- (lr_results$p_value_1 < 0.05)
lr_results$significant_0.1 <- (lr_results$p_value_1 < 0.1)
lr_results$significant_0.2 <- (lr_results$p_value_1 < 0.2)
# lr_results[order(lr_results$p_value_1),]
print("Number of variables considering each level of significance using Logistic test")
print(colSums(lr_results[,10:12], na.rm = TRUE))
lr_results %>% lr_results[order(lr_results$p_value_1, decreasing = FALSE), 'p_value_1' , drop = FALSE]

# deviance analysis (Null deviance: 58.352  on 62  degrees of freedom = N-1)
lr_results$deviance_diff <- 1 - pchisq((58.352 - lr_results$deviance), 1, lower.tail = FALSE)
lr_results$significant_dev <- (lr_results$deviance_diff > 0.95)
# significant differences in deviances
sum(lr_results$significant_dev)

## univariate models with 1 df (because the predictor variable is constant)
print("Columns 9,10,13,17,30,37 are CONSTANT, that's why they p_values are so high")
lr_results[c(9,10,13,17,30,37),'p_value_1']


feat_lr <- rownames(lr_results[lr_results$p_value_1 < 0.2 ,])
data_lr <- data %>% select(all_of(feat_lr), Outcome)
dim(data_lr)
```

### Multicollinearity
Calculate Variance Inflation Factor (VIF) to avoid multicollinearity. 
VIF larger than 5 or 10 is large and indicate a high level of multicollinearity.

```{r, echo = FALSE}
# including all features selected by lr test
#, na.action = na.exclude
model_lr <- glm(Outcome ~ ., data=data_lr, family = binomial(link = logit))
summary(model_lr)
print(VIF(model_lr))
```

