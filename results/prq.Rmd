---
title: "Puppy Raiser Questionnaire vs Outcome (Success, Fail)"
author: "Marinara Marcato"
output: 
  html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/marinara.marcato/Project/Scripts/dog_questionnaires")
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE) 

# install.packages("PRROC")
library(DescTools)
# plot
library(ggplot2)
library(ggpubr)
library(cowplot)

# datasets
library(plyr)
library(dplyr)
library(tidyverse)
library(reshape2)

library(ggsci)  # colors for the graphs - npg for nature
library(broom)  # convert r output into tibbles
library(xtable) # latex table output

# machine learning/stats
library(mlbench)
library(caret)
library(recipes)
library(PRROC)  # calculates precision recall curve

```

```{r output, include = FALSE, results = "hide", message = FALSE}
# save dataframes to csv and print LaTeX table
tab_results <- function(df, name, caption=NULL) {

    # remove the dots from the rownames
    rownames(df) <- gsub("[.]", " ", rownames(df))
    
    path = paste("results/prq/", name, ".csv", sep = "")

    # save csv file
    write.csv(df, path)
    cat("dataframe saved to ", path)
    
    # latex code for table
    # print(xtable(df,
    #     caption = paste(caption, ".", sep = ""),
    #     label = paste("T-prq-", name, sep = "")),
    #     caption.placement = "top")
}

# save images as png and print LaTeX table
fig_results <- function(plot, name, caption = NULL, label = NULL){

    path = paste("results/prq/", name, ".png", sep = "")
    
    # if label is not given, use name
    if (is.null(label)){
        label = name
    }
    # save png
    suppressMessages(ggsave(filename = path, 
                plot = plot + theme(text = element_text(size = 20)),
                width = 12, height = 8))
    cat("Image saved at", path)

    # latex code for image
#     cat("\n\nStart LaTeX code\n\n",
#             paste("\\begin{figure}[!h]\n\\centering\n\\caption{", paste(caption, ".", sep = ""),"}","\n\\label{F-prq-", label, "}\n\\includegraphics[width = 11cm]{",path,"}\n\\end{figure}", sep = ""), 
#             "\n\nEnd LaTeX Code\n\n")
}
```

# Introduction 
In order to objectively evaluate trainee guide dogs personality, their puppy raisers filled out the standardised questionnaire Canine Behavioural Assessement & Research Questionnaire (C-BARQ) around the time they were due to start formal training.
This document shows the data analysis carried out to investigate the association between ratings given by the puppy raisers and the dog's training outcome.
Statistical methods will be used to test the hypothesis that there is a relationship between personality ratings and training outcome (Success, Fail).

# Data Exploration

Importing data and converting variables to adequate data types.
```{r, echo = FALSE}
prq = read.csv('data/2022-08-08-PRQ_C-BARQ.csv', stringsAsFactors=TRUE)
# colnames(prq)
# converting date types
prq$Timestamp = as.Date(prq$Timestamp, format= "%Y-%m-%d")
prq$DOB = as.Date(prq$DOB, format= "%Y-%m-%d")
prq$DOA = as.Date(prq$DOA, format= "%Y-%m-%d")
prq$End.Date = as.Date(prq$End.Date, format= "%Y-%m-%d")
prq$Duration = as.numeric(gsub(" .*$", "", prq$Duration))
```

## Demographics

The number of dogs in the Puppy Raiser Questionnaire dataset. Selection criteria: dogs who successed training (assistance and guide dogs) and dogs withdrawn for behavioural reasons.
```{r, echo = FALSE}
cat('Number of dogs:', length(prq$Code))
cat('Training Outcome:')
table(prq$Outcome)
```

Analysing categorical demographic data: Sex, Breed. There was only one German Shepherd and Golden Doodle dogs in the sample, their breeds were relabeled as "Other" for the data analysis.
```{r, echo = FALSE}
print(table(prq$Sex))
print("Original classes")
table(prq$Breed)
# merging breed categories
levels(prq$Breed)[levels(prq$Breed) == "LRx"] <- "LRxGR"
levels(prq$Breed)[levels(prq$Breed) =="GS" | levels(prq$Breed) =="GRxPoodle"] <- "Other"
print("Processed classes")
table(prq$Breed)
```

Analysing age at arrival to the training centre and age at assessment when the questionnaire was completed:
```{r, echo = FALSE}
n <- dim(prq)[1]

prq$Age.at.Arrival <- prq$DOA - prq$DOB
mean <- mean(prq$Age.at.Arrival)
std <- sd(prq$Age.at.Arrival)
margin <- qt(0.975,df=n-1)*sd(std)/sqrt(n)

cat('Age at Arrival: Mean', round(mean/30.417, 2), 
            'Standard Deviation', round(std/30.417, 2))
            # 'Confidence Interval', round((mean-margin)/30.417, 2), round((mean+margin)/30.417, 2)


prq$Age.at.Assessment <- prq$Timestamp - prq$DOB
mean <- mean(prq$Age.at.Assessment)
std <- sd(prq$Age.at.Assessment)
margin <- qt(0.975,df=n-1)*sd(std)/sqrt(n)

cat('Age at Assessment: Mean', round(mean/30.417, 2), 
            'Standard Deviation', round(std/30.417, 2))
            # 'Confidence Interval', round((mean-margin)/30.417, 2), round((mean+margin)/30.417, 2)
```

Calculate statistics of duration of training for the dogs that were withdrawn from training. 
```{r, echo = FALSE}
# Duration of training before withdrawal in weeks
duration <- prq %>% filter(Outcome == "Fail") %>% select(Duration)/7
print('Duration of Training in weeks')
summary(duration)

h <- ggplot(duration, aes(x=Duration)) +
 geom_histogram(binwidth = 1) +
 xlab("Duration (Weeks)") +
 ylab("Number of Dogs") + theme_bw()

h

fig_results(h, name = "duration-histogram",
            caption = "Duration of training in weeks for dogs that were withdrawn from training for behavioural reasons.")
```

## Descriptive Statistics
The C-BARQ contains 100 items which were scored by the Puppy Raisers in a scale from 'Never', 'Seldom', 'Sometimes', 'Usually', 'Always' and encoded in a scale from 0 to 4. 
Out of the 100 items, 78 items are used to calculate 14 factors and the remaining 22 items are myscellaneous.
The questionnaire data are kept as numeric, rather than being converted to factors, so the information about the ordering is kept.
The descriptive statistics of the questionnaire data shown below are calculated and saved as a csv.  
Missing data is also analysed. 

```{r, echo = FALSE}
data = prq %>% select(starts_with(c('I_', 'F_')), Sex, Breed, Outcome)
print("Items")
colnames(data[1:100])
print("Factors, Demographic and Outcome")
str(data[101:117])
# FACTOR CALCULATIONS  - Items used 1–76 and 91–92; Items NOT used 77-90 and 93-100 
```

```{r, echo = FALSE}
# calculate descriptive statistics
stats <- data.frame(do.call(rbind, lapply(data[1:114], summary)))

# missing values, there is something weird about the NAs calculations using summary
stats$NA.s <- colSums(is.na(data[1:114]))
print('Features sorted by number of missing rows')
print(stats[order(stats$NA.s, decreasing = TRUE)[1:18], 'NA.s', drop = FALSE])

# histogram of missing values in original dataset
h <- ggplot(stats, aes(x=NA.s)) +
    geom_histogram(binwidth = 1) +
    xlab("Number of Missing values ") +
    ylab("Number of Variables") + theme_bw()

# 28 NAs -> Item 49 nails clipped by someone in the house
# 12-10 NAs -> Because of no other dog  in household -> Items 33,34,32,35

# save csv and print latex code
tab_results(stats, name = "descriptive-statistics")
```

## Feature Selection
### Criteria 1, 2 and 3: Univariate Logistic Regression

Logistic regression was used to investigate whether there was a statistically significant difference between the behaviours reported by Puppy Raisers and the Training Outcome of the dogs.
C-BARQ Correlation with Training Outcome. 

Breeds (p = 0.44 and p = 0.16) and Sex (p = 0.61) were not significantly associated with training outcome.
```{r, echo = FALSE}
# GLM function in R will predict the probability of the LAST class 
# R defaults to alphabetical order, therefore, between [Fail Success], it will predict Success
# releveling to have Success as FIRST class so Fail is the last class which will be predicted
data$Outcome <- relevel(data$Outcome, "Success")

# univariate logistic regression using one predictor and outcome
lr_models <- lapply(data[-length(data)], 
                        function(x) glm(formula = Outcome ~ x, 
                        data = data, 
                        family = binomial(link = logit), na.action = na.exclude))
lr_result <- lapply(lr_models, function(x) c(coef(summary(x)), summary(x)$deviance))


summary(lr_models[1])
## univariate models with 3 dfs (Breed)
lr_breeds <- data.frame(transpose(lr_result[116]))
colnames(lr_breeds) <- c("estimate_0", "estimate_1", "estimate_2", 
                    "se_0", "se_1", "se_2", "z_value_0", "z_value_1", "z_value_2", 
                    "p_value_0", "p_value_1", "p_value_2", "deviance")
print(lr_models[116])
cat('Difference between Other and LR: \t', lr_breeds$p_value_1, '\t -> not significant')
cat('Difference between Other and LRxGR: \t', lr_breeds$p_value_2, '\t -> not significant')

## univariate models with up to 2 dfs (items are ints)
lr_results <- data.frame(do.call(rbind,lr_result[1:115]))
colnames(lr_results) <- c("estimate_0", "estimate_1", 
                    "se_0", "se_1", "z_value_0", "z_value_1",
                    "p_value_0", "p_value_1", "deviance")

## univariate models with 1 df (because the predictor variable is constant)
print("Columns 9,10,13,17,30,37 are CONSTANT, that's why they p_values don't make sense")
lr_results[c(9,10,13,17,30,37),'p_value_1']

# save csv and print latex code
tab_results(lr_results, name = "univariate-logistic-regression")
``` 

Converting logistic regression result to odds ratio and confidence intervals. 
```{r, echo = FALSE}
lr <- lr_results %>% select(estimate_1, p_value_1) # se_1, z_value_1,
colnames(lr) <- c("Estimate", "p-value")
lr$OR <- exp(lr$Estimate)
# list of dataframes of CI for each of the models on the list
lr_cis <- lapply(lr_models[-length(lr_models)], function(x) as.data.frame(exp(confint(x, level = 0.95))))
# list of dataframes removing the CI for the intercept
lr_cis <- lapply(lr_cis, function(x) x[2,])
# turn list of dataframes into a dataframe
lr_ci <- bind_rows(lr_cis, .id = 'x')
# replace rownames with column with the name of the variables
lr_ci <- lr_ci %>% remove_rownames %>% column_to_rownames(var="x")

# bind CIs
lr <- cbind(lr, lr_ci)

# save csv and print latex code
tab_results(lr,
    caption = "Univariate logistic regression model estimates, p-value, odds ratio (OR) and confidence interval (CI)",
    name = "lr-or-ci")
```

Analysing p-values and deviance.
Analysing deviance of full model compared to the null model. 
Reduction in deviance must be significant (chi-squared test) for the model to be considered a good fit.
```{r, echo = FALSE}
# CRITERION 1: pvalue analysis
print("Number of features considering each level of significance using Logistic Regression p-value & difference in deviance test")
lr_results$significant_0.05 <- (lr_results$p_value_1 > 0) & (lr_results$p_value_1 < 0.05) 
lr_results$significant_0.1 <- (lr_results$p_value_1 > 0) & (lr_results$p_value_1 < 0.1) 
lr_results$significant_0.2 <- (lr_results$p_value_1 > 0) & (lr_results$p_value_1 < 0.2) 
print(colSums(lr_results[,10:12], na.rm = TRUE))
# inclusion of X96,98 and F3,6 in feature set p<0.2 compared to with p<0.05 

# CRITERION 2: deviance analysis (Null deviance: 58.352  on 62  degrees of freedom = N-1)
lr_results$deviance_diff <- pchisq((58.352 - lr_results$deviance), 1, lower.tail = FALSE)
lr_results$deviance_sign <- (lr_results$deviance_diff < 0.05)
# significant differences in deviances
cat('Number of features whose univariate models resulted in a significant difference in deviance: ', sum(lr_results$deviance_sign))

```

Feature selection based on the univariate logistic regression p-value and deviance analysis. 
This reduced feature set contains all factors and only items that were NOT included in the calculation of statistically significant factor with p<0.05 (i.e. Items 1,27 an 75 and some myscellaneous items 77-90, 93-100).
```{r, echo = FALSE}
lr_results %>% filter(significant_0.05 ==TRUE & deviance_sign == TRUE) %>% select(estimate_1, p_value_1)
# CRITERIA 1 and 2
print("All features with level of significance < 0.05 using Univariate Logistic Regression p-value test")
data_2 <- data %>% 
    select(all_of(lr_results %>% filter(significant_0.05 ==TRUE & deviance_sign == TRUE) %>% rownames()), Outcome)
cat("Full Feature Set with p<0.05 and reduction in deviance\t", dim(data_2))

# CRITERION 3
# items that were significant but not used to calculate significant factors 1, 27, 75
# items not used to calculate any factors 77-90 and 93-100
print("Keeping items 1, 27, 75 and anything between 77-90 and 93-100")
data_3 <- data_2  %>% 
        select(contains(c("I_01", "I_27", "I_75", as.character(c(77:90, 93:100)), 'Sex', 'Breed', 'F_')), Outcome)
cat("Reduced Feature Set with p<0.05\t", dim(data_3))
colnames(data_2)
```

### Criterion 4: Missing Data

PRQ, missing values per column and per row. Removing features with more than 5% missing data (i.e. I_77, I_93).
```{r, echo = FALSE}
# reduced dataset
NA.s <- unlist(lapply(data_3, function (x) sum(is.na(x))))
NA.s
# save csv and print latex code
tab_results(data.frame(NA.s), name = "missing",
        caption = "Variables considered for the reduced feature set and number of missing values.")
print(which(NA.s > 5))
# removing 93 and 77 contains as they contained >5% data missing
data_4 <- data_3  %>% select(-contains(as.character(c(77, 93))))
cat("Reduced Feature Set with p<0.05 and < 5% missing data\t", dim(data_4))
```

### Criterion 5: Correlation

Removing features with more than 0.75 correlation (i.e. F_07)
```{r, echo = FALSE}
# change col names for the plot
colnames(data_4) <- unlist(lapply(strsplit(colnames(data_4),"[.]"), function(x) x[1]))

# calculate correlation matrix
correlationMatrix <- round(abs(cor(data_4 %>% select(-c("Outcome")), use = "pairwise.complete.obs")),2)
plot <- ggplot(data = melt(correlationMatrix), aes(x=Var1, y=Var2, fill=value)) + 
        geom_tile() + theme(axis.text.x = element_text(angle = 45, vjust = 0.1)) +
        xlab("Variables") + ylab(NULL)
plot

# save .png and latex code
fig_results(plot = plot, name = "correlation",
            caption = "Correlation Matrix for variables considered for the reduced feature set")

# find attributes that are highly corrected (ideally > 0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75, names = TRUE, exact = TRUE)
# print indexes of highly correlated attributes
cat("Highly correlated variable to be removed", highlyCorrelated)

data_reduced <- data_3  %>% select(-contains(as.character(c(77, 93, highlyCorrelated))))
cat("Reduced Feature Set with p<0.05 and < 5% missing data and <75% correlated\t", dim(data_reduced))
```


### Visualization
Plotting the items and factors that will be used for modelling.
```{r, echo = FALSE}
plot_discrete <- function(var){
    
    plot1 <- ggplot(data_reduced, aes_string( x = var, fill = 'Outcome', width = 1)) + 
            geom_bar(position = "dodge") + 
            theme(legend.position = c(0.84,0.88), text = element_text(size = 20)) +
            # scale_x_discrete("Rating", limits = c(0:4), breaks = c(0:4), labels = c(0:4)) +
            expand_limits(x = c(0,4))

    plot2 <- ggplot(data_reduced, aes_string( x = 'Outcome', y = var)) + 
            geom_violin(position = "dodge", width = 0.8, aes(color = Outcome, fill = Outcome), alpha = 0.2) +
            geom_boxplot(position = "dodge", aes(colour = Outcome), fill = "white",  width = 0.3) +
            theme(legend.position = "none", text = element_text(size = 20)) +
            expand_limits(y = c(0,4)) +
            ylab("Rating")

    plot3 <- plot_grid(plot1, plot2, rel_widths = c(2, 1), labels = "AUTO") 
    title <- ggdraw() + 
            draw_label(gsub("[.]", " ", var), fontface = 'bold')
    
    plot <- plot_grid(title, plot3, ncol = 1, rel_heights = c(0.1, 1))

    fig_results(plot = plot3,
                    name = gsub("[.]", "-", var),
                    caption = gsub("[.]", " ", var),
                    label = unlist(strsplit(var, "[.]"))[1])
    
    plot
}

feat_items <- data_reduced %>% select(-Outcome, -contains('F_')) %>% colnames
lapply(feat_items, plot_discrete)

plot_continuous <- function(var){

    # bin = (max(data_reduced[var], na.rm = TRUE) - min(data_reduced[var], na.rm = TRUE)) / 5
    max_x <- max(data_reduced[var], na.rm = TRUE)
    min_x <- min(data_reduced[var], na.rm = TRUE)
    bin <- seq(min_x, max_x, (max_x - min_x)/10)
    # print(bin)
    
    plot1 <- ggplot(data_reduced, aes_string(x = var, fill = 'Outcome')) + 
            geom_histogram(position = "dodge", breaks = bin) +
            theme(legend.position = c(0.84,0.88), text = element_text(size = 20))

    plot2 <- ggplot(data_reduced, aes_string( x = 'Outcome', y = var)) + 
            geom_violin(position = "dodge", width = 0.8, aes(color = Outcome, fill = Outcome), alpha = 0.2) +
            geom_boxplot(position = "dodge", aes(colour = Outcome), fill = "white",  width = 0.3) +
            theme(legend.position = "none",text = element_text(size = 20)) +
            ylab("Rating")

    plot3 <- plot_grid(plot1, plot2, rel_widths = c(2, 1), labels = "AUTO")

    title <- ggdraw() + 
            draw_label(gsub("S[.]|[.]", " ", var), fontface = 'bold')
    
    plot <- plot_grid(title, plot3, ncol = 1, rel_heights = c(0.1, 1))

    fig_results(plot = plot3, 
                    name = gsub("[.]", "-", var),
                    caption = gsub("[.]", " ", var),
                    label = unlist(strsplit(var, "[.]"))[1])

    plot
}   

feat_factors <- data_reduced %>% select(contains('F_')) %>% colnames
lapply(feat_factors, plot_continuous)

```


# Multivariate Model

## Multicollinearity 
Calculate Variance Inflation Factor (VIF) to avoid multicollinearity. 
The glm models were built on the reduced feature sets and exclude any sample containing NAs.
VIF larger than 5 or 10 is large and indicate a high level of multicollinearity.

The resulting multivariate logistic regression models are NOT looking good, p_values are all roughly 1.
Mainly because they have small sample size (examples with NAs were removed).
VIF values indicate a high degree of multicollinearity. 

```{r, echo = FALSE}
cat("VIF reduced")
model_lr_reduced <- glm(Outcome ~ ., data=data_reduced, family = binomial(link = logit), na.action = na.exclude)
summary(model_lr_reduced)
tab_results(data.frame(tidy(model_lr_reduced), row.names = 1),
            name = "multicollinearity",
            caption = "Multivariate model using the reduced feature set for multicollinearity analysis.")

# N = 47 samples do NOT contain NAs in 0.05 REDUCED dataset, M = 12 features
vif_reduced <- VIF(model_lr_reduced)
print(vif_reduced)
# save csv and print latex code
tab_results(data.frame(tidy(vif_reduced), row.names = 1),
            name = "VIF", 
            caption = "VIF for the reduced feature set")
```

## Preprocessing: Normalization + Imputation + PCA
PCA was performed using the entire reduced feature set. 
The "recipes" package was used to perform preprocessing (missing value imputation + normalization + PCA).
[link](https://recipes.tidymodels.org/reference/step_pca.html),
[Recipes documentation](https://cran.r-project.org/web/packages/recipes/recipes.pdf),
[Example Recipes](https://www.rebeccabarter.com/blog/2019-06-06_pre_processing/)

## Recursive Feature Elimination (RFE) + Multivariate Logistic Regression (LR)
Feature selection was performed using the caret packages rfe function.
Logistic Regression was used to model the dataset and Leave One Subject Out Cross Validation was employed to validate the results.
[Caret RFE](https://search.r-project.org/CRAN/refmans/caret/html/rfe.html), 
[Caret RFE Control](https://search.r-project.org/CRAN/refmans/caret/html/rfeControl.html), 
[Examples using RFE with Recipes](http://topepo.github.io/caret/recursive-feature-elimination.html#rferecipes)
[Example RFE + RF as predictor](https://towardsdatascience.com/effective-feature-selection-recursive-feature-elimination-using-r-148ff998e4f7), 
[RFE + ROC as metric](https://stackoverflow.com/questions/18242692/r-package-caret-rfe-function-how-to-customize-metric-to-use-auc).

```{r, echo = FALSE}
# GLM predicts the SECOND class -> make sure Fail is second class
data_reduced$Outcome <- relevel(data_reduced$Outcome, ref = "Success")
cat('predicting second class:', levels(data_reduced$Outcome))

model_recipe <- recipe(Outcome ~ ., data = data_reduced )  %>%
        step_impute_mean(all_numeric()) %>%
        step_normalize(all_numeric()) %>%
        step_pca(all_predictors(), threshold = 0.95)

# Setting ROC as the metric for the Logistic Regression function
# lrFuncs$summary <- twoClassSummary 
lrFuncs$summary <- prSummary 
set.seed(42)

ctrl <- rfeControl(functions = lrFuncs,         # Logistic Regression
                method = "cv",                  # Cross Validation
                number = 63,                    # Number of folds
                # method = "LOOCV",
                saveDetails = TRUE,
                returnResamp = "all",
                allowParallel = FALSE,
                rerank = TRUE,
                verbose = FALSE)

# Recursive Feature Elimination with feat_lr
model_rfe <- rfe(model_recipe,                 # predict Outcome using all other variables
                data = data_reduced,           # selecting the features from univariate lr
                sizes = 1:10,                  # from 1 to 10 variables
                rfeControl = ctrl,
                # metric = "Sens",               # optimising Specificity to avoid False Failures -> sens/spec are swapped in RFE
                metric = "Precision",
                maximize = TRUE)

warnings()
print(model_rfe)
model <- summary(model_rfe$fit)
print(model)
```

Model fitness with deviance analysis. Performance metrics ROC and PR curves. 
```{r, echo = FALSE}
# model fitness
dev = model$null.deviance - model$deviance
deg = model$df.null - model$df.residual
cat('\ndeviance difference: ', dev)
cat('\ndf difference: ', deg)
cat('\nlevel of significance: ', pchisq(dev, deg, lower.tail = FALSE))
cat('\nthe model is a good fit: ', pchisq(dev, deg, lower.tail = FALSE) < 0.05)

# cross validated predictions for perfromance analysis
df_perf <- model_rfe$pred %>% 
            filter(Variables == 1) %>% 
            select(rowIndex, Fail, pred, obs) %>% 
            rename("Probability" = "Fail", "Predicted" = "pred", "Outcome" = "obs")
df_perf$Status <- prq$Status

# logit function, calculate y given the probability(x)
y <- function(x){ return(log(1/( 1/x - 1))) }
df_perf$Estimate <- y(df_perf$Probability)

# calculate performance metrics ROC
confusionMatrix(data = df_perf$Predicted, reference = df_perf$Outcome, positive = "Fail")

roc_curve <- roc.curve(scores.class0 = df_perf$Probability,
             weights.class0 = abs(as.numeric(df_perf$Outcome)-1),
             curve=TRUE)
roc_curve
png('results/prq/roc-curve.png')
plot(roc_curve, xlab = "Specificity")
dev.off()

# calculate performance metrics PR
confusionMatrix(data = df_perf$Predicted, reference = df_perf$Outcome, positive = "Fail", mode = "prec_recall")

pr_curve <- pr.curve(scores.class0 = df_perf$Probability,
             weights.class0 = abs(as.numeric(df_perf$Outcome)-1),
             curve=TRUE)
pr_curve

png('results/prq/pr-curve.png')
plot(pr_curve)
dev.off()

```

```{r, echo = FALSE}
th_fail = 0.7
th_success = 0.3

# releveling for the colours in the plot
df_perf$Outcome <- relevel(df_perf$Outcome, "Fail")
df_perf$Status <- relevel(df_perf$Status, "W")

print("Probability predicted by the LR using PRQ data vs true Outcome")
plot <- ggplot(df_perf, aes(x = Estimate, y = Probability, group = Outcome ))  +
    # bottom - green
    geom_rect(aes(xmin = -Inf, xmax = y(th_success), ymin = 0, ymax = th_success), 
            fill = "#99ff99", alpha = 0.2, color = "white") + 
    # top - orange
    geom_rect(aes(xmin = y(th_fail), xmax = Inf, ymin = th_fail, ymax = 1), 
            fill = "#ffff99", alpha = 0.2, color = "white") +  
    theme(legend.position = c(0.14,0.88), text = element_text(size = 20)) +
    geom_point(aes(shape=Outcome, color=Outcome))
plot

fig_results(plot = plot, name = 'logit-outcome', 
            caption = "Probability predicted by the best logistic regression model using \acrshort{cbarq} data vs true Outcome")


print("Probability predicted by the LR using PRQ data vs true Status")
# plot Logit vs Status
plot <- ggplot(df_perf, aes(x = Estimate, y = Probability, color = Status )) +
    # bottom - green
    geom_rect(aes(xmin = -Inf, xmax = y(th_success), ymin = 0, ymax =  th_success), 
            fill = "#99ff99", alpha = 0.2, color = "white") + 
    # top - orange
    geom_rect(aes(xmin = y(th_fail), xmax = Inf, ymin =  th_fail, ymax = 1), 
            fill = "#ffff99", alpha = 0.2, color = "white") +  
    theme(legend.position = c(0.14,0.88), text = element_text(size = 20)) +
    geom_point(aes(shape=Status, color=Status))
plot

fig_results(plot = plot, name = 'logit-status', 
            caption = "Probability predicted by the best logistic regression model using \acrshort{cbarq} data vs true Status")

print("Estimate and Probabilities per training outcome status")
df_perf %>% group_by(Status) %>% dplyr::summarize(Mean = mean(Estimate, na.rm=TRUE))
df_perf %>% group_by(Status) %>% dplyr::summarize(Mean = mean(Probability, na.rm=TRUE))

cat("Predicted probability <", th_success, " -> Green flag ")
print("Dogs flagged green are likely to SUCCEED, true outcome count and status proportion:")
table(df_perf %>% filter(Probability < th_success) %>% pull(Outcome))
prop.table(table(df_perf %>% filter(Probability < th_success) %>% pull(Status)))

cat("Predicted probability >", th_fail, "-> Yellow flag")
print("Dogs flagged green are likely to FAIL, true outcome count and status proportion:")
table(df_perf %>% filter(Probability > th_fail) %>% pull(Outcome))
prop.table(table(df_perf %>% filter(Probability > th_fail) %>% pull(Status)))

cat(th_success, " < Predicted probability <", th_fail, "-> no flags")
table(df_perf %>% filter(Probability > th_success & Probability < th_fail) %>% pull(Status))
```

## Interpretation

The best Logistic Regression model is used to investigate the effect of the principal components on the training outcome.
The estimates were exponentiated to get the Odds Ratio (OR). The 95% Confident Interval (CI) of the ORs was also calculated. 
The OR for PC01 is 0.44, this means that the probability of withdrawal decreases by (0.44-1) 66% for every unit increase of PC1.
We are 95% confident that a unit increase in PC01 results in a 33 to 75% (0.25-1 = 0.75, 0.67-1 = 0.33) less odds of being withdrawn from training.

```{r, echo = FALSE}
results_reduced <- as.data.frame(coef(summary(model_rfe$fit)))
results_reduced$OR <- exp(results_reduced$Estimate)
results_reduced <- cbind(results_reduced, exp(confint(model_rfe$fit, level = 0.95)))
print("Results from the model created with the reduced feature set")
print(results_reduced)

# save csv and print latex code
tab_results(results_reduced,
    caption = "Best logistic regression model using selected by RFE",
    name = "rfe-lr")
```

## Feature Importance

### Explained Variance
```{r, echo = FALSE}
# PCA variance
dc_pca_var <- as.data.frame(tidy(model_rfe$recipe, number = 3, type = "variance"))
dc_pca_var <- dc_pca_var %>% spread(key = "terms", value = value) %>% select(-c(id))
dc_pca_var$component <- mapvalues(dc_pca_var$component, from = 1:12, 
    to = c('PC01', 'PC02', 'PC03', 'PC04', 'PC05', 'PC06', 'PC07', 'PC08', 'PC09', 'PC10', 'PC11', 'PC12'))
colnames(dc_pca_var) <- make.names(names(dc_pca_var)) # fixing column names with space

print("Explained Variance per Principal Component (Scree Plot)")
dc_pca_var$Included = factor(c("Yes", "No", "No", "No", "No", "No", "No", "No", "No", "No", "No", "No"))
plot <- ggplot(dc_pca_var, aes(x = component, y = percent.variance)) + #, fill = Included)
    geom_bar(stat='identity', position = 'dodge', width = 0.8)+
    xlab("Principal components") +
    ylab("Explained Variance (%)") 
plot

fig_results(plot = plot, name = 'pc-explained-variance', 
            caption = "Explained variance per principal component (Scree Plot)")
```

### Coefficient Loadings

Analysis of the principal component loadings that were used in the best Multivariate Logistic Regression Model.

The 5 highest loading values in PC1 come from the variables 
"F_11 Excitability"
"F_08 Dog directed fear"
"F_06 Nonsocial fear"
"F_10 Separation related behaviour"
"I_27 Toward cats squirrels or other small animals entering your yard" 
This indicates that this principal component places most variation in these variables. 

```{r, echo = FALSE}
# PCA coefficients
df_pca_coef <- as.data.frame(tidy(model_rfe$recipe, number = 3, type = "coef"))  %>% 
                filter(component == 'PC1') %>% select(terms, value) 

plot <- ggplot(df_pca_coef, aes(x=unlist(lapply(strsplit(terms,"[.]"), function(x) x[1])), y=value)) +
    geom_bar(stat='identity', position='dodge', width = 0.8) +
    xlab("C-BARQ items and factors - Predictor Variables") +
    ylab("Principal components") 
plot    

fig_results(plot = plot, name = 'pc-loading',
            caption = "PC01 coefficient loading from original items and factors")

# save csv and print latex code
tab_results(df_pca_coef %>% remove_rownames %>% column_to_rownames(var="terms"), 
            name = 'pc-loading', caption = 'PC01 coefficient loading from original items and factors')

# figuring out the righest loading items for the PC1
df_pca_coef %>% arrange(desc(abs(value))) %>% select(terms, value)
```

# Conclusion

Completing this questionnaire before training (Week 0) would allow assistance dog training organisations to learn more about the dogs starting training. 
Results from this objective assessment would assist practitioners in making informed decisions when analysing which dogs should be withdrawn for training. 
The model could be used to flag dogs likely to be withdrawn from training for behavioural reasons. 
Dog trainers could consider the output to re-assess and adjust the training programme for flagged dogs in order to address behavioural issues.
Considering the higher TPR achieved by the Reduced model, that might be a better choice when employing this system to correcly identify unsuitable dogs for the training programme.

